{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROJETO 3 - LIMPANDO DADOS DO OPENSTREETMAP\n",
    "\n",
    "O projeto é composto pelos seguintes arquivos:\n",
    "\n",
    "     1 - main.ipynb (arquivo principal com as consultas e o relatório)\n",
    "     2 - saoPaulo-OSM.osm (arquivo com o xml usado na análise): https://www.openstreetmap.org/export#map=13/-23.5628/-46.6265\n",
    "     4 - audit.py (arquivo onde foi feito a auditoria dos dados)\n",
    "     5 - cleaning2csv.py (arquivo onde foi feito a limpeza e extração para CSVs)\n",
    "     6 - saoPaulo-OSM.db (arquivo de banco de dados)\n",
    "     7 - schema.sql (arquivo com as tabelas usadas)\n",
    "     8 - schema.py (arquivo para criação das tabelas)\n",
    "   \n",
    "   \n",
    "Optou-se por deixar o código python nos arquivos audit.py/cleaningtocsv.py e manipulá-lo por aqui para que o relatório ficasse mais simples de seguir.\n",
    "\n",
    "A cidade escolhida foi São Paulo - Brasil. Apesar de morar em Brasília, optei por São Paulo por ser um cidade mais conhecida (o que provavelmente faça com que ela tenha mais usuários contribuindo) e com uma densidade populacional maior. No entando, ressalte-se que a área não compreende toda cidade de São Paulo, mas a sua região central e arredores, visto que o mapa ficaria inviável em tamnho para executar em um computador pessoal.\n",
    "\n",
    "A primeira parte desse relatório trata-se da Extração e Limpeza dos Dados, na segunda parte é a Análise dos dados em SQL  e, por último, uma conclusão e possíveis trabalhos futuros.\n",
    "\n",
    "REFERÊNCIAS: https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Código realizado para auditoria\n",
    "%run audit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 38131,\n",
      " 'meta': 1,\n",
      " 'nd': 2510996,\n",
      " 'node': 1692838,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 5428,\n",
      " 'tag': 903140,\n",
      " 'way': 240135}\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Conta quantas tags de cada tipo possuem no arquivo xml\n",
    "test(\"count_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 766448, 'lower_colon': 136146, 'other': 546, 'problemchars': 0}\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tipos de tags\n",
    "test(\"key_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Jesuíno Maciel => Rua Dr. Jesuíno Maciel\n",
      "Azevedo Junior => Rua Azevedo Junior\n",
      "Coronel Melo Oliveira => Rua Coronel Melo Oliveira\n",
      "Rocha Pombo => Rua Rocha Pombo\n",
      "Capital Federal => Rua Capital Federal\n",
      "Sapopemba => Avenida Sapopemba\n",
      "Pires da Mota => Rua Pires da Mota\n",
      "Álvares Penteado => Rua Álvares Penteado\n",
      "Saturno => Rua Saturno\n",
      "Al. Ribeirão Preto => Alameda Ribeirão Preto\n",
      "Al. José Maria Lisboa => Alameda José Maria Lisboa\n",
      "Al. Santos => Alameda Santos\n",
      "Al. Sarutaiá => Alameda Sarutaiá\n",
      "Rue Arthur Azevedo => Rua Arthur Azevedo\n",
      "Av. São Miguel Paulista, 9.167 - sp => Avenida São Miguel Paulista, 9.167 - sp\n",
      "Av. Liberdade => Avenida Liberdade\n",
      "Agissê => Rua Agissê\n",
      "Rúa Dom José de Barros => Rua Dom José de Barros\n",
      "Espírito Santo => Rua Espírito Santo\n",
      "rua Paulo Orozimbo => Rua Paulo Orozimbo\n",
      "rua => Rua\n",
      "Castro Alves => Rua Castro Alves\n",
      "Conselheiro Furtado => Rua Conselheiro Furtado\n",
      "Martim Francisco => Rua Martim Francisco\n",
      "Bueno de Andrade => Rua Bueno de Andrade\n",
      "praça dom josé gaspar => Praça dom josé gaspar\n",
      "Alfonso Bovero => Rua Alfonso Bovero\n",
      "Manoel Ramos Paiva => Rua Manoel Ramos Paiva\n"
     ]
    }
   ],
   "source": [
    "#Auditoria no nome das ruas\n",
    "test(\"street_audit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postcode error - format is wrong : 03011-001632\n",
      "postcode error - format is wrong : 03009-030299\n",
      "postcode error - format is wrong : 03009-030299\n",
      "postcode error - format is wrong : 03009-030299\n",
      "postcode error - format is wrong : 03009-030299\n",
      "postcode error - format is wrong : 03009-030299\n",
      "postcode error - format is wrong : 01046-020165\n",
      "postcode error - format is wrong : 01050-00081\n",
      "postcode error - format is wrong : 03162-0302258\n"
     ]
    }
   ],
   "source": [
    "#Auditoria do código postal\n",
    "test(\"postcode_audit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Limpeza e extração de dados para os arquivos CSVs\n",
    "%run cleaning2csv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA WRAGLING - Limpeza e extração dos dados\n",
    "\n",
    "Foram utilizados três amostras, uma com menos de 1mb de tamanho, utilizada principalmente para testar o código, outra com aproximadamente 12 mb e uma com pouco mais de 100mb.\n",
    "\n",
    "ANÁLISES\n",
    "\n",
    "Antes de realizar a limpeza e extração dos dados, foi criado um banco com uma amostra \"crua\", recém saída do OSM. Visto que foram feitas algumas consultas para conhecer os dados melhor e, procurar por possíveis anomalias nos campos.\n",
    "\n",
    "1 - A primeira análise foi verificar se existiam alguma anomalidade nas \"keys\", principalmente através da exitência de problem chars. Como é visto na execução acima, não foram encontrados.\n",
    "\n",
    "2 - Após isso, e seguindo mais ou menos o roteiro no que foi visto no curso, realizei a auditoria das ruas. Onde foram econtrados alguns erros de abreviação (Av.) e outros de omissão, como Álvares ao invés de Rua Álvares.\n",
    "\n",
    "3 - O próximo item auditado foram os códigos postais, onde verificou-se que alguns estavam fora do padrão (00000-000 e, no caso de SP 01000-000 a 09999-999). Desta forma, os que estavam fora do padrão, para não confudir, receberam \"wrong size\" ou \"wrong area\" como valor. Todos os códigos também foram padronizados em 0xxxx-xxx, a maioria estava nesse formato, mas alguns apresentavam somente o número, sem o hífem.\n",
    "\n",
    "4 - Além desses itens, também foram padronizados os telefones, que eram escritos de diversas forma (com e sem o código de área ou o código do país, com e sem hífem ou com parentêses delimitando o código de SP). Todos os telefones ficaram com o padrão +55 11xxxxxxxx para telefones fixos e +55 11xxxxxxxxx para telefones celulares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ANÁLISE DOS DADOS EM SQL\n",
    "\n",
    "Tamanho dos arquivos\n",
    "\n",
    "SaoPaulo-RegiaoCentral.osm ......... 398 MB\n",
    "SaoPaulo-RegiaoCentral.db .......... 229 MB\n",
    "nodes.csv ............. 148 MB\n",
    "nodes_tags.csv ........ 8 MB\n",
    "ways.csv .............. 15 MB\n",
    "ways_tags.csv ......... 21 MB\n",
    "ways_nodes.cv ......... 61 MB\n",
    "\n",
    "\n",
    "Número total de nodes:\n",
    "sqlite> SELECT COUNT(*) FROM nodes;\n",
    "1692838\n",
    "\n",
    "Número total de ways:\n",
    "sqlite> SELECT COUNT(*) FROM ways;\n",
    "240135\n",
    "\n",
    "Número de usuários:\n",
    "sqlite> SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\n",
    "674\n",
    "\n",
    "\n",
    "Número dos 10 usários que mais contribuíram:\n",
    "sqlite> SELECT COUNT(*), e.user FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY COUNT(*) DESC LIMIT 10;\n",
    "1739637,Bonix-Mapper\n",
    "91123,Bonix-Importer\n",
    "56691,\"O Fim\"\n",
    "4040,MCPicoli\n",
    "3943,naoliv\n",
    "3142,AjBelnuovo\n",
    "2626,ygorre\n",
    "2328,EduardoGananca\n",
    "1799,Wololo\n",
    "1727,Geogast\n",
    "\n",
    "Como é possível perceber o usuário Bonix-Mapper é responsável por quse 90% dos dados. \n",
    "\n",
    "\n",
    "Número de usúario que contribuíram somente uma vez:\n",
    "sqlite> SELECT COUNT(*) FROM (SELECT e.user FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user HAVING COUNT(*) = 1);\n",
    "214\n",
    "\n",
    "Número de ruas mapeadas na análise:\n",
    "sqlite> SELECT COUNT(DISTINCT(e.value)) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) e GROUP BY e.key HAVING e.key = \"street\";\n",
    "1273\n",
    "\n",
    "São Paulo possui 48623 logadouro, dados de 2016 (fonte: https://super.abril.com.br/cultura/quantas-ruas-existem-em-sao-paulo/), porém como a área foi selecionada manualmente na região central, essa consulta nos mostra que a maioria da cidade não foi coberta.\n",
    "\n",
    "Como a área foi selecionanda manualmente e São Paulo possui um região metropolitana, convém verificar se a área em questão compreende parte de outras cidades da região metropolitana.\n",
    "\n",
    "sqlite> SELECT DISTINCT(e.value) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) e WHERE e.key = \"city\";\n",
    "São Paulo\n",
    "Mooca\n",
    "\n",
    "Mooca pertence à cidade de São Paulo, a consulta também apresentou outas formas de escrita de São Paulo. \n",
    "\n",
    "Seleciona as principais \"amenities\" que compõem o conjunto de dados\n",
    "slite>SELECT value, COUNT(*) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) WHERE key='amenity' GROUP BY value ORDER BY COUNT(*) DESC LIMIT 10;\n",
    "parking|2306\n",
    "restaurant|798\n",
    "bank|422\n",
    "fuel|288\n",
    "fast_food|285\n",
    "pub|189\n",
    "bicycle_rental|185\n",
    "pharmacy|164\n",
    "taxi|163\n",
    "school|157\n",
    "\n",
    "São Paulo possui uma densidade populacional altíssima e consquentemente um número de veículos assombroso, tanto é que a cidade possuí \"rodízio\" de placas na semana. Sem surpresas quanto ao número de estacionamentos.\n",
    "\n",
    "As 10 cozinhas mais comuns na região:\n",
    "sqlite> SELECT COUNT(*), value FROM nodes_tags JOIN (SELECT id FROM nodes_tags WHERE value=\"restaurant\") as a ON a.id = nodes_tags.id WHERE key = \"cuisine\" GROUP BY value ORDER BY COUNT(*) DESC LIMIT 10;\n",
    "83|regional\n",
    "32|japanese\n",
    "22|pizza\n",
    "16|italian\n",
    "14|burger\n",
    "12|arab\n",
    "8|vegetarian\n",
    "5|brazilian\n",
    "5|chinese\n",
    "5|international\n",
    "\n",
    "Brasileiro gosta muito de comida japonesa, nada estranho aqui.\n",
    "\n",
    "Os bancos com mais agências na região central:\n",
    "sqlite> SELECT COUNT(*), value FROM nodes_tags JOIN (SELECT id FROM nodes_tags WHERE value=\"bank\") as a ON a.id = nodes_tags.id WHERE key=\"name\" GROUP BY value ORDER BY COUNT(*) DESC LIMIT 10;\n",
    "61|Itaú\n",
    "55|Santander\n",
    "47|Bradesco\n",
    "46|Banco do Brasil\n",
    "31|Caixa Econômica Federal\n",
    "27|Banco Itaú\n",
    "23|Banco Bradesco\n",
    "14|Caixa\n",
    "13|Bradesco Prime\n",
    "12|Banco Santander\n",
    "\n",
    "Aqui, como trabalhos futuros seria necessário excluir a redundância nos nomes. Como é possível perceber são somente 5 bancos diferentes. Um ideia adicional também seria não permitir, no sistema OSM, a inserção de um banco com nome diferentes.\n",
    "\n",
    "\n",
    "Religiões mais populares\n",
    "sqlite> SELECT COUNT(*), value FROM nodes_tags JOIN (SELECT id FROM nodes_tags WHERE value=\"place_of_worship\") as a ON a.id = nodes_tags.id WHERE key=\"religion\" GROUP BY value ORDER BY COUNT(*) DESC LIMIT 10;\n",
    "68|christian\n",
    "5|buddhist\n",
    "4|jewish\n",
    "1|hindu\n",
    "\n",
    "O Brasil é uma país majoritariamente cristão, sem surpresas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMENTÁRIOS E IDEIAS\n",
    "\n",
    "Alguns pontos podem ser discutidos com essa breve análise. Primeiro, poucos usuário do OpenStreetMap.org são responsáveis por áreas bastante grande, o que o torna não tão colaborativo assim. Segundo, para se ter uma ideia melhor da cidade seria necessário pegar as outras regiões, não somente a região central. Terceiro, muitos campos precisam de uma limpesa maior, como os valores de algumas amenities, exemplo a amenity bank, que possui algumas redundâncias nos nomes. \n",
    "\n",
    "Mesmo com as limitações descritas, foi possível utilizar bem os conhecimento do módulos para realizar um bom data wrangling dos dados, praticar a linguagem python e criar um banco de dados SQL do zero e realizar algumas consultas, que mostram um pouco da realidade da cidade de São Paulo no Brasil.\n",
    "\n",
    "\n",
    "TRABALHO FUTUROS\n",
    "\n",
    "Como trabalhos futuros, seria interessante pegar toda a cidade de São Paulo e realizar um data wrangling em todos os campos dos quais se pretende analizar melhor. Além disso, seria interessante que o OSM utilizasse ferramentas para tentar amenizar a redundâcia de alguns 'v's nas tags, uma sugestão seria a criação de campos com um padrão definido, por exemplo, quando alguém for inserir um endereço, limitar o sufixo dos mesmos, ou seja, o colaborador poderá adicinar uma \"Rua\" somente com essa forma de escrita e não com \"R.\" ou \"Rúa\". Outra sugestão é que ao inserir um campo novo, esse campo ficaria como padrão, por exemplo, ao inserir o nome de um banco, a primeira forma de escrevê-lo ficaria como padrão para as demais. Obviamente, o benefício da implanatação dessas ideias seria gigantesco, visto que o data wrangling ficaria bem menos trabalhoso, porém, as dificuldades seria bastante grandes, pelas complexidade em implementar tal modificações na plataforma do OSM e, também, porque dificultaria mais para os colaboradores inserirem dados, o que poderia  fazer com que alguns desistissem de dar suas contribuições.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
